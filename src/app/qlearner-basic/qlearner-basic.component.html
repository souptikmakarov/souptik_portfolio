<h1>Q-Learning with Dyna-Q</h1>


<h2>1 Overview</h2>

<p>A very simple implementation of the Q-Learning and Dyna-Q solutions to the reinforcement learning problem.</p>
<p>This implementation is tested on a 2D grid robot world.</p>



<h2>Test Environment</h2>
The navigation task takes place in a 10 x 10 grid world. The particular environment is expressed in a CSV file of integers, where the value in each position is interpreted as follows:
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>
<ul>
    <li>blank space.</li>
    <li>an obstacle.</li>
    <li>the starting location for the robot.</li>
    <li>the goal location.</li>
    <li>quicksand.</li>
</ul>